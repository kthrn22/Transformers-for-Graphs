{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0-1 0-2 0-3 0-4\n",
    "# 1-2 1-4\n",
    "# 2-3 2-4\n",
    "# 3-4\n",
    "\n",
    "node_feat = torch.from_numpy(np.random.rand(5, 3))\n",
    "edge_index = np.array([[0, 1],\n",
    "                        [1, 0],\n",
    "                        # [0, 2],\n",
    "                        # [2, 0],\n",
    "                        [0, 3],\n",
    "                        [3, 0],\n",
    "                        [0, 4],\n",
    "                        [4, 0],\n",
    "                        [1, 2],\n",
    "                        [2, 1],\n",
    "                        [1, 4],\n",
    "                        [4, 1],\n",
    "                        [2, 3],\n",
    "                        [3, 2],\n",
    "                        [2, 4],\n",
    "                        [4, 2],\n",
    "                        [3, 4],\n",
    "                        [4, 3],]).T\n",
    "edge_index = torch.from_numpy(edge_index).to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edge_feat = np.random.rand(edge_index.shape[1] + 1, 3)\n",
    "#edge_feat[-1] = 0\n",
    "#edge_feat = torch.from_numpy(edge_feat)\n",
    "edge_feat = torch.from_numpy(np.random.rand(edge_index.shape[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 3, 3, 4])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_vertices, target_vertices = edge_index\n",
    "\n",
    "# out_degree: source -> target, in_degree: (for target) target <- source\n",
    "torch.zeros((node_feat.shape[0])).scatter_add_(0, source_vertices, torch.ones(source_vertices.shape)).to(torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 3, 3, 4])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((node_feat.shape[0])).scatter_add_(0, target_vertices, torch.ones(target_vertices.shape)).to(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def calculate_in_and_out_degree(edge_index, num_nodes):\n",
    "    source_index, target_index = edge_index\n",
    "    out_degree = torch.zeros((num_nodes)).scatter_add_(0, source_index, torch.ones(source_index.shape)).to(torch.long)\n",
    "    in_degree = torch.zeros((num_nodes)).scatter_add_(0, target_index, torch.ones(target_index.shape)).to(torch.long)\n",
    "\n",
    "    return in_degree, out_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_edge_index_to_adjacency_list(edge_index, num_nodes, edge_weights = None):\n",
    "    adjacency_list = [[] for _ in range(num_nodes)]\n",
    "    source_vertices, target_vertices = edge_index   \n",
    "    \n",
    "    if edge_weights is None:\n",
    "        edge_weights = torch.ones(edge_index.shape[-1])\n",
    "    \n",
    "    for edge_id, (source_vertex, target_vertex, edge_weight) in enumerate(zip(source_vertices, target_vertices, edge_weights)):\n",
    "        source_vertex, target_vertex, edge_weight = source_vertex.item(), target_vertex.item(), edge_weight.item()\n",
    "\n",
    "        adjacency_list[source_vertex].append((target_vertex, edge_weight, edge_id))\n",
    "\n",
    "    return adjacency_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def trace_shortest_path(root_node, current_node, adjacency_list, distances, max_shortest_len):\n",
    "    if distances[current_node] == -1 or root_node == current_node:\n",
    "        return [-1] * max_shortest_len\n",
    "\n",
    "    trace, shortest_path = [current_node], []\n",
    "    while trace[-1] != root_node:\n",
    "        u = trace[-1]\n",
    "        \n",
    "        for v, edge_len, edge_id in adjacency_list[u]:\n",
    "            if distances[u] == distances[v] + edge_len:\n",
    "                trace.append(v)\n",
    "                shortest_path.append(edge_id)\n",
    "                break\n",
    "\n",
    "    shortest_path += [-1] * (max_shortest_len - len(shortest_path))\n",
    "\n",
    "    return shortest_path\n",
    "\n",
    "def find_shortest_path(root_node, num_nodes, adjacency_list, return_paths: bool = True):\n",
    "    # compute the shortest distance from root node to other nodes in the graph\n",
    "    # return the paths if needed\n",
    "\n",
    "    distances = [-1] * num_nodes\n",
    "    distances[root_node] = 0\n",
    "    shortest_distances = [(distances[root_node], root_node)]\n",
    "\n",
    "    while shortest_distances:\n",
    "        _, u = heapq.heappop(shortest_distances)\n",
    "\n",
    "        for v, edge_distance, _ in adjacency_list[u]:\n",
    "            if distances[v] == -1 or distances[u] + edge_distance < distances[v]:\n",
    "                distances[v] = distances[u] + edge_distance\n",
    "                heapq.heappush(shortest_distances, (distances[v], v))\n",
    "\n",
    "    if return_paths:\n",
    "        shortest_paths = []\n",
    "        for node_id in range(num_nodes):\n",
    "            shortest_path = trace_shortest_path(root_node, node_id, adjacency_list, distances, 5)\n",
    "            shortest_paths.append(shortest_path)\n",
    "\n",
    "        return distances, shortest_paths\n",
    "\n",
    "    return distances\n",
    "\n",
    "def shortest_path(num_nodes, edge_index, return_paths: bool = True):\n",
    "    adjacency_list = convert_edge_index_to_adjacency_list(edge_index, num_nodes)\n",
    "    \n",
    "    # 2d array shortest_distances[i][j]: shortest distance from node i to node j, -1 , shape [N, N]\n",
    "    # if the path from i to j doesnt exist\n",
    "    shortest_distances = torch.from_numpy(np.array([find_shortest_path(root_node, num_nodes, adjacency_list, False) \n",
    "                                        for root_node in range(num_nodes)])).to(torch.int64)\n",
    "    max_shortest_len = torch.max(shortest_distances)\n",
    "\n",
    "    # trace shortest path, shape [N, N, max_shortest_len]\n",
    "    # shortest_paths[i][j] = [e_1, e_2, ... ,e_n], the shortest path from node i to node j, e_i is the i_th edge's index\n",
    "    # padded with -1\n",
    "    if return_paths:\n",
    "        shortest_paths = np.array([[trace_shortest_path(root_node, node_id, adjacency_list, shortest_distances[root_node], max_shortest_len)\n",
    "                                for node_id in range(num_nodes)] for root_node in range(num_nodes)])\n",
    "        shortest_paths = torch.from_numpy(shortest_paths).permute(1, 0, 2)\n",
    "\n",
    "        return shortest_distances, shortest_paths\n",
    "\n",
    "    return shortest_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "shortest_distances, shortest_paths = shortest_path(node_feat.shape[0], edge_index, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_in_degree + z_out_degree\n",
    "class CentralityEncoding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_degree, undirected_graph: bool) -> None:\n",
    "        super(CentralityEncoding, self).__init__()\n",
    "        \n",
    "        if undirected_graph:\n",
    "            self.degree_embedding = nn.Embedding(max_degree + 1, embedding_dim, padding_idx = 0)        \n",
    "        else:\n",
    "            self.in_degree_emdedding = nn.Embedding(max_degree + 1, embedding_dim, padding_idx = 0)\n",
    "            self.out_degree_embedding = nn.Embedding(max_degree + 1, embedding_dim, padding_idx = 0)\n",
    "\n",
    "        self.max_degree = max_degree\n",
    "        self.undirected_graph = self.undirected_graph\n",
    " \n",
    "    def forward(self, in_degree, out_degree):\n",
    "        # in_degree, out_degree shape: [N]\n",
    "        in_degree = torch.clamp(in_degree, min = 0, max = self.max_degree)\n",
    "        out_degree = torch.clamp(out_degree, min = 0, max = self.max_degree)\n",
    "\n",
    "        # shape: [N, embedding_dim]\n",
    "        if self.undirected_graph:\n",
    "            # unidirected_graph -> in_degree == out_degree \n",
    "            return self.degree_embedding(in_degree)\n",
    "        else:\n",
    "            return self.in_degree_emdedding(in_degree) + self.out_degree_embedding(out_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialEncoding(nn.Module):\n",
    "    def __init__(self, max_path_len, num_heads):\n",
    "        super(SpatialEncoding, self).__init__()\n",
    "        self.bias = nn.Embedding((max_path_len + 1) * num_heads, 1)\n",
    "        self.max_path_len = max_path_len\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "    def forward(self, shortest_distances, max_shortest_path_len):\n",
    "        max_path_len = min(self.max_path_len, max_shortest_path_len)\n",
    "        shortest_distances = torch.clamp(shortest_distances, min = 0, max = max_path_len)\n",
    "        indices = [i for i in range((self.max_path_len + 1) * self.num_heads)]\n",
    "        # [len, num_heads, 1] -> [len, 1, num_heads]\n",
    "        spatial_encoding = self.bias(torch.tensor(indices).reshape(self.max_path_len + 1, self.num_heads)).permute(0, 2, 1)\n",
    "        # shape [N, N, 1, num_heads] -> [N, N, num_heads]\n",
    "        spatial_encoding = spatial_encoding[shortest_distances].squeeze(2)\n",
    "\n",
    "        return spatial_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = SpatialEncoding(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = nn.Embedding(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3566, -1.2094, -0.3377,  0.0986],\n",
       "        [ 0.3583,  0.5515, -0.7362, -0.1878],\n",
       "        [ 0.4680,  0.9014,  1.4959,  0.6430]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(torch.tensor([0, 1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3566, -1.2094, -0.3377],\n",
       "        [ 0.0986,  0.3583,  0.5515],\n",
       "        [-0.7362, -0.1878,  0.4680],\n",
       "        [ 0.9014,  1.4959,  0.6430]], grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(torch.tensor([0, 1, 2])).reshape(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_heads = 4\n",
    "# len = 2\n",
    "a = nn.Embedding(8, edge_feat.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3774,  0.0843, -0.3887,  0.1960],\n",
       "         [-0.2527, -0.4564, -0.7476,  0.9558],\n",
       "         [-2.2308,  0.5785,  0.5679, -0.4715]],\n",
       "\n",
       "        [[ 0.6289,  0.0766, -0.6899, -2.3844],\n",
       "         [ 2.6950,  1.1180, -0.0757, -0.6474],\n",
       "         [-0.7192,  0.0058, -0.2198, -0.4381]]], grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(torch.tensor([i for i in range(8)]).reshape(2, 4)).permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5, 2, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_feat[shortest_paths].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeEncoding(nn.Module):\n",
    "    def __init__(self, max_path_len, edge_feat_dim, num_heads):\n",
    "        super(EdgeEncoding, self).__init__()\n",
    "        self.max_path_len = max_path_len\n",
    "        self.edge_feat_dim = edge_feat_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.weight_embedding = nn.Embedding((max_path_len + 1) * num_heads, edge_feat_dim)\n",
    "\n",
    "    def forward(self, shortest_paths, edge_feat, max_shortest_path_len):\n",
    "        max_path_len = min(self.max_path_len, max_shortest_path_len)\n",
    "        # shape [n, n, path_len]\n",
    "        tmp_shortest_paths = shortest_paths[:, :, : max_path_len]\n",
    "        # shape [n, n, path_len, edge_feat_dim]\n",
    "        padded_edge_feat = torch.cat((edge_feat, torch.zeros(1, edge_feat.shape[-1])), dim = 0)\n",
    "        edge_embedding = padded_edge_feat[tmp_shortest_paths]\n",
    "\n",
    "        # reshape weight_embedding to [path_len, num_heads, edge_feat_dim] \n",
    "        # -> permute to get final shape [path_len, edge_feat_dim, num_heads]\n",
    "        indices = [i for i in range(max_path_len * self.num_heads)]\n",
    "        weight_embedding = self.weight_embedding(torch.tensor(indices).reshape(max_path_len, self.num_heads)).permute(0, 2, 1)\n",
    "        \n",
    "        # shape [N, N, path_len, edge_feat_dim], [path_len, edge_feat_dim, num_heads] -> [N, N, num_heads]\n",
    "        edge_encoding = torch.einsum('xyld,ldh->xyh', edge_embedding.to(weight_embedding.dtype), weight_embedding)\n",
    "\n",
    "        return edge_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, in_dim, num_heads, dropout, use_linear_bias = True):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert in_dim % num_heads == 0\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = in_dim // num_heads\n",
    "\n",
    "        self.linear_Q = nn.Linear(in_dim, in_dim, bias = use_linear_bias)\n",
    "        self.linear_K = nn.Linear(in_dim, in_dim, bias = use_linear_bias)\n",
    "        self.linear_V = nn.Linear(in_dim, in_dim, bias = use_linear_bias)\n",
    "        self.linear_out = nn.Linear(in_dim, in_dim, bias = use_linear_bias)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        return\n",
    "\n",
    "    def scaled_dot_attention(self, Q, K):\n",
    "        attention_score = torch.matmul(Q, K.permute(1, 0))\n",
    "        attention_score /= np.sqrt(self.head_dim)\n",
    "\n",
    "        return attention_score\n",
    "\n",
    "    def forward(self, node_feat, edge_index, max_path_len, edge_feat = None, attention_mask = None):\n",
    "        Q = self.linear_Q(node_feat)\n",
    "        K = self.linear_K(node_feat)\n",
    "        V = self.linear_V(node_feat)\n",
    "\n",
    "        # [N, NH, head_dim]\n",
    "        Q = Q.view(-1, self.num_heads, self.head_dim)\n",
    "        K = K.view(-1, self.num_heads, self.head_dim)\n",
    "        V = V.view(-1, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Q shape [n, num_heads, head_dim] -> [num_heads, N, head_dim]\n",
    "        Q = Q.permute(1, 0, 2)\n",
    "        # K shape [n, num_heads, head_dim] -> [num_heads, head_dim, N]\n",
    "        K = K.permute(1, 2, 0)\n",
    "        \n",
    "        # matmul Q K -> [num_heads, n, n]\n",
    "        attention_score = torch.matmul(Q, K)\n",
    "        attention_score /= np.sqrt(self.head_dim)\n",
    "        # permute attention_score shape -> [n, n, num_heads]\n",
    "        attention_score = attention_score.permute(1, 2, 0)\n",
    "        \n",
    "        shortest_distances, shortest_paths = shortest_path(node_feat.shape[0], edge_index, return_paths = True)\n",
    "        max_shortest_path_len = torch.max(shortest_distances)\n",
    "        \n",
    "        spatial_encoder = SpatialEncoding(max_path_len, self.num_heads)\n",
    "        spatial_encoding = spatial_encoder(shortest_distances, max_shortest_path_len)\n",
    "\n",
    "        attention_score += spatial_encoding\n",
    "        if edge_feat is not None:\n",
    "            edge_encoder = EdgeEncoding(max_path_len, edge_feat.shape[-1], self.num_heads)\n",
    "            edge_encoding = edge_encoder(shortest_paths, edge_feat, max_shortest_path_len)\n",
    "\n",
    "            attention_score += edge_encoding\n",
    "\n",
    "        # attention_mask shape [n, n]\n",
    "        if attention_mask is None:\n",
    "            attention_mask = shortest_distances < 0\n",
    "        else:\n",
    "            attention_mask = attention_mask.to(torch.bool)\n",
    "            \n",
    "        attention_score[attention_mask.to(torch.bool)] = float(\"-inf\")\n",
    "\n",
    "        # shape [n, n, num_heads]\n",
    "        normalized_attention_score = nn.functional.softmax(attention_score, dim = -1)\n",
    "        normalized_attention_score = self.dropout(normalized_attention_score)\n",
    "\n",
    "        # normalized_attention_score, v -> out_node_feat\n",
    "        # [n, n, num_heads], [n, num_heads, head_dim] -> [num_heads, n, n], [num_heads, n, head_dim]\n",
    "        normalized_attention_score = normalized_attention_score.permute(2, 0, 1)\n",
    "        V = V.permute(1, 0, 2)\n",
    "        # -> [num_heads, n, head_dim] -> permute to [n, num_heads, head_dim] -> reshape to [n, num_heads * in_dim]\n",
    "        out_node_feat = torch.matmul(normalized_attention_score, V)\n",
    "        out_node_feat = out_node_feat.permute(1, 0, 2).view(-1, self.num_heads * self.head_dim)\n",
    "        out_node_feat = self.linear_out(out_node_feat)\n",
    "\n",
    "        return out_node_feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphormerLayer(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, num_heads, dropout):\n",
    "        super(GraphormerLayer, self).__init__()\n",
    "        assert in_dim % num_heads == 0\n",
    "        self.multihead_attention_layer_norm = nn.LayerNorm(in_dim)\n",
    "        #def __init__(self, in_dim, num_heads, dropout, use_linear_bias = True):\n",
    "        self.MultiHeadAttention_layer = MultiHeadAttention(in_dim, num_heads, dropout, True)\n",
    "        \n",
    "        self.ffn_layer_norm = nn.LayerNorm(in_dim)\n",
    "        self.FNN_layer = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, in_dim),\n",
    "            nn.Dropout(dropout),)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, node_feat, edge_index, max_path_len, edge_feat = None, attention_mask = None):\n",
    "        # 1st Residual Connection: x = MHA(LN(x)) + x\n",
    "        x_init = node_feat\n",
    "        x = self.multihead_attention_layer_norm(node_feat)\n",
    "        #def forward(self, node_feat, edge_index, max_path_len, edge_feat = None, attention_mask = None):        \n",
    "        x = self.MultiHeadAttention_layer(x, edge_index, max_path_len, edge_feat, attention_mask)\n",
    "        x = self.dropout(x)\n",
    "        x = x + x_init\n",
    "\n",
    "        # 2nd Residual Connection: x = FFN(LN(x)) + x\n",
    "        x_init = x\n",
    "        x = self.ffn_layer_norm(x)\n",
    "        x = self.FNN_layer(x)\n",
    "        x = x + x_init\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "GL = GraphormerLayer(node_feat.shape[-1], 12, 3, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0625, -0.0944,  0.1058],\n",
       "        [ 0.7347,  0.3676,  0.6618],\n",
       "        [ 0.3198,  0.0890,  1.2540],\n",
       "        [-0.0868, -0.1765,  0.3840],\n",
       "        [ 0.2124, -0.0201,  0.7187]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GL(node_feat.to(torch.float32), edge_index, 10, edge_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (v3.8.10:3d8993a744, May  3 2021, 09:09:08) \n[Clang 12.0.5 (clang-1205.0.22.9)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
